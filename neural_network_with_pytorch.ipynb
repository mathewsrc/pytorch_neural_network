{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGNZsfeF8nrR6r7CR0QeRA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/pytorch_neural_network_mnist/blob/master/neural_network_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pytorch - Neural Network MNIST**"
      ],
      "metadata": {
        "id": "oBYn931Ze1j-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aN-219a1LERS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import click\n",
        "try:\n",
        "  import torch\n",
        "  from torch import nn, optim\n",
        "  from torchvision import datasets, transforms\n",
        "except:\n",
        "  !pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @click.command()\n",
        "# @click.option('--input_size', default=784, help='Size of the input layer of the model.')\n",
        "# @click.option('--output_size', default=10, help='Size of the output layer of the model.')\n",
        "def create_model(input_size, output_size):\n",
        "    \"\"\"\n",
        "    This function creates a sequential feedforward neural network model for image classification.\n",
        "\n",
        "    Args:\n",
        "        input_size (int, optional): Size of the input to the model. In this case, the input size is 784,\n",
        "        representing the size of a 28x28 image after being flattened. Defaults to 784.\n",
        "        output_size (int, optional): Number of classes that the model should predict. In this case, \n",
        "        the output size is 10, representing the number of digits from 0-9. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        A PyTorch `nn.Sequential` object representing the model.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(nn.Linear(input_size, 228),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(228, 64),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(64, output_size),\n",
        "                  nn.LogSoftmax(dim=1)\n",
        "                 )"
      ],
      "metadata": {
        "id": "X3q-YhlgL_1N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, cost, optimizer, epoch):\n",
        "  \"\"\"\n",
        "    Train a machine learning model.\n",
        "    \n",
        "    Parameters:\n",
        "    model (nn.Module): The model to be trained.\n",
        "    train_loader (DataLoader): The training data loader.\n",
        "    cost (function): The cost function used to evaluate the model's performance during training.\n",
        "    optimizer (Optimizer): The optimization algorithm used to update the model's parameters.\n",
        "    epoch (int): The number of iterations over the entire training data.\n",
        "    \n",
        "    Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Loop through each epoch\n",
        "  for e in range(epoch):\n",
        "    # Initialize running loss to 0\n",
        "    running_loss = 0\n",
        "    # Initialize the number of correct predictions to 0\n",
        "    correct = 0\n",
        "    # Loop through each batch in the train_loader\n",
        "    for data, target in train_loader:\n",
        "      # Reshape the data tensor to have shape (batch_size, -1)\n",
        "      data = data.view(data.shape[0], -1)\n",
        "      # Zero the gradients of the model parameters\n",
        "      optimizer.zero_grad()\n",
        "      # Get the predictions from the model\n",
        "      pred = model(data)\n",
        "      # Calculate the loss between the predictions and the target\n",
        "      loss = cost(pred, target)\n",
        "      # Add the loss to the running total of the loss\n",
        "      running_loss += loss\n",
        "      # Compute the gradients of the loss with respect to the model parameters\n",
        "      loss.backward()\n",
        "      # Update the model parameters using the optimizer\n",
        "      optimizer.step()\n",
        "      # Find the index of the maximum prediction for each sample in the batch\n",
        "      pred = pred.argmax(dim=1, keepdim=True)\n",
        "      # Increase the number of correct predictions\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    # Print the average loss and accuracy over the entire training dataset at the end of each epoch\n",
        "    print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")"
      ],
      "metadata": {
        "id": "nVg_nyr0M-cs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import click\n",
        "\n",
        "@click.command()\n",
        "@click.option('--model', type=click.File('rb'), help='The trained model file')\n",
        "@click.option('--train_loader', type=click.File('rb'), help='The training data loader file')\n",
        "@click.option('--cost', type=click.File('rb'), help='The cost function file')\n",
        "@click.option('--optimizer', type=click.File('rb'), help='The optimizer file')\n",
        "@click.option('--epoch', type=int, default=10, help='The number of iterations over the entire training data')\n",
        "def cli(model, train_loader, cost, optimizer, epoch):\n",
        "    \"\"\"Train a machine learning model.\"\"\"\n",
        "    # Load the model, train_loader, cost function, and optimizer from the files\n",
        "    model = pickle.load(model)\n",
        "    train_loader = pickle.load(train_loader)\n",
        "    cost = pickle.load(cost)\n",
        "    optimizer = pickle.load(optimizer)\n",
        "    # Call the train function\n",
        "    train(model, train_loader, cost, optimizer, epoch) "
      ],
      "metadata": {
        "id": "wsp32CTCYA-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    \"\"\"\n",
        "    This function tests the accuracy of a given neural network model on a test dataset.\n",
        "\n",
        "    Arguments:\n",
        "        model (nn.Module): The model to be tested.\n",
        "        test_loader (DataLoader): The test data in the form of PyTorch DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    # Initialize the number of correct predictions to 0\n",
        "    correct = 0\n",
        "    # Turn off gradient computation to speed up evaluation\n",
        "    with torch.no_grad():\n",
        "        # Loop through each batch in the test_loader\n",
        "        for data, target in test_loader:\n",
        "            # Reshape the data tensor to have shape (batch_size, -1)\n",
        "            data = data.view(data.shape[0], -1)\n",
        "            # Get the predictions from the model\n",
        "            output = model(data)\n",
        "            # Find the index of the maximum prediction for each sample in the batch\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # Increase the number of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    # Print the test accuracy\n",
        "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')\n",
        "\n"
      ],
      "metadata": {
        "id": "n7flqr6tSrMk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import click\n",
        "\n",
        "@click.command()\n",
        "@click.option('--model', type=click.File('rb'), help='The trained model file')\n",
        "@click.option('--train_loader', type=click.File('rb'), help='The training data loader file')\n",
        "def cli(model, train_loader):\n",
        "    \"\"\"Train a machine learning model.\"\"\"\n",
        "    # Load the model, train_loader from the files\n",
        "    model = pickle.load(model)\n",
        "    train_loader = pickle.load(train_loader)\n",
        "    # Call the test function\n",
        "    test(model, train_loader) "
      ],
      "metadata": {
        "id": "zVJ1bBHDYpPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# @click.command()\n",
        "def training_transform():\n",
        "    \"\"\"\n",
        "    This function returns a compose of data transforms for the training data.\n",
        "\n",
        "    Returns:\n",
        "        transforms.Compose: A compose of data transforms to be applied to the training data.\n",
        "    \"\"\"\n",
        "    return transforms.Compose([\n",
        "        # Randomly flip the image horizontally with a probability of 0.5 (Data Augumentation)\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image tensor with mean (0.1307,) and standard deviation (0.3081,)\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])"
      ],
      "metadata": {
        "id": "Q4c2CfOSUtWO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# @click.command()\n",
        "def testing_transform():\n",
        "  \"\"\"\n",
        "    Define a transformation for the test data.\n",
        "    \n",
        "    Returns:\n",
        "    A PyTorch `transforms.Compose` object.\n",
        "  \"\"\"\n",
        "  return transforms.Compose([\n",
        "    # Convert the image to a PyTorch tensor\n",
        "    transforms.ToTensor(),\n",
        "    # Normalize the image tensor with mean (0.1307,) and standard deviation (0.3081,)\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "  ])\n"
      ],
      "metadata": {
        "id": "cA5uNOEMVH_d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Hyperparameters\n",
        "batch_size = 64\n",
        "epoch = 10\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('data/', download=True, train=True, transform=training_transform())\n",
        "testset = datasets.MNIST('data/', download=True, train=False, transform=testing_transform())\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Size of the input \n",
        "input_size = 784\n",
        "\n",
        "# Number of classes\n",
        "output_size = 10\n",
        "\n",
        "# Create model\n",
        "model = create_model(input_size, output_size)\n",
        "\n",
        "# Cost function using Negative Log Likelihood Loss\n",
        "cost = nn.NLLLoss()\n",
        "\n",
        "# Stochastic Gradient Descent optimizer with learning rate 0.001 and momentum 0.9\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model for the specified number of epochs\n",
        "train(model, train_loader, cost, optimizer, epoch)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxTBUeyPMCm7",
        "outputId": "2e00f5dc-8340-4463-fce2-31927a9b2651"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 0.01602686196565628, Accuracy 70.30833333333332%\n",
            "Epoch 1: Loss 0.007675544358789921, Accuracy 84.65166666666667%\n",
            "Epoch 2: Loss 0.006209364160895348, Accuracy 87.88666666666667%\n",
            "Epoch 3: Loss 0.005043025128543377, Accuracy 90.39500000000001%\n",
            "Epoch 4: Loss 0.004245693329721689, Accuracy 92.15%\n",
            "Epoch 5: Loss 0.0037167943082749844, Accuracy 93.08333333333333%\n",
            "Epoch 6: Loss 0.0033402012195438147, Accuracy 93.68666666666667%\n",
            "Epoch 7: Loss 0.003047898644581437, Accuracy 94.24%\n",
            "Epoch 8: Loss 0.002804572694003582, Accuracy 94.68333333333334%\n",
            "Epoch 9: Loss 0.00259191426448524, Accuracy 95.15333333333334%\n",
            "Test set: Accuracy: 9488/10000 = 94.88%)\n"
          ]
        }
      ]
    }
  ]
}